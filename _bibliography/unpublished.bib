---
---
@phdthesis{grebenkovabsc,
  abbr = {BsC},
  abstract={В работе исследуется задача построения модели глубокого обучения. Предлагается способ контроля ее сложности. Под сложностью модели понимается минимальная длина описания, минимальный объем информации, который требуется для передачи информации о модели и о выборке. Сложность рассматривается как параметр, который может быть задан на этапе получения модели на основе имеющихся вычислительных и других эксплуатационных требований. Чтобы контролировать сложность модели, вводятся вероятностные предположения о распределении параметров модели глубокого обучения.  В работе предложены три формы регуляризации, которые позволяют управлять распределением параметров модели. Предлагается метод оптимизации параметров модели, основанный на представлении модели глубокого обучения в виде гиперсети с использованием байесовского подхода. Под гиперсетью понимается модель, которая генерирует параметры оптимальной модели.  Предлагается подход, максимизирующий нижнюю вариационную оценку байесовской обоснованности модели. Вариационная оценка рассматривается как условная величина, зависящая от требуемой сложности модели. Для анализа качества предлагаемого алгоритма проведены эксперименты на выборках MNIST и CIFAR.},
  abstract_en={The paper is devoted to deep learning model complexity control. The complexity is an amount of the  information that is required to transfer information about the model and the dataset.  We consider a compexity of the model as a parameter that can be set during model inference step based on computational budget and other operational requirements for the model. In order to control the model complexity we introduce a probabilistic assumptions about the distribution of parameters of the deep learning model. The paper instigates three forms of the regularization that allow to control the model parameter distribution. We consider the model evidence as a conditional value that depends on the required model complexity. The proposed method is based on the representation of deep learning model parameters in the form of hypernetwork output. A hypernetwork is a model that generates parameters of an optimal model.  We analyze this method in the computational experiments on the MNIST and CIFAR datasets.},
  author_en= {Olga Grebenkova},
  author       = {Гребенькова Ольга},   
  title_en = {Model generation with complexity control using Bayesian hypernetworks, Bachelor thesis}, 
  title        = {Порождение моделей заданной сложности с использованием байесовских гиперсетей, бакалаврский диплом},
  note_en = {Scientific adviser: Oleg Bakhteev, PhD},
  note ={Научный руководитель: к.ф.-м.н.  Бахтеев О.Ю.},
  year         = 2021,
}



@phdthesis{phdthesis,
  abbr = {PhD},
  author_en= {Oleg Bakhteev},
  author       = {Бахтеев, Олег},   
  title_en = {Baeysian suboptimal deep learning structure selection, PhD thesis}, 
  title        = {Байесовский выбор субоптимальной структуры модели глубокого обучения, диссертация к.ф.-м. н. },
  html = {http://www.frccsc.ru/diss-council/00207305/diss/list/bahteev_oy},
  pdf={http://www.frccsc.ru/sites/default/files/docs/ds/002-073-05/diss/26-bahteev/ds05-26-bahteev_main.pdf?28},
  note_en = {Scientific adviser: Vadim Strijov, DSc},
  note ={Научный руководитель: д.ф.-м.н. Стрижов В. В.},
  year         = 2020,
}

@unpublished{VBTA,
abbr = {arXiv},
author = "Kuznetsova, Rita and Bakhteev, Oleg and Ogaltsov, Alexandr",
title = "Variational learning across domains with triplet information",
arxiv={1806.08672},
year={2020}
}


@unpublished{habr_klin,
abbr={Хабр},
author= "Антиплагиат",
title_en="Klingon language tutorial",
title= "Самоучитель клингонского",
note={Хабр. Соавтор статьи},
year={2020},
html={https://habr.com/ru/company/antiplagiat/blog/507848/},
abbr_en={Habr},
author_en = "Antiplagiat company",
note_en={It-blog. Article co-author.},
}


@unpublished{habr_troe,
abbr={Хабр},
author= "Антиплагиат",
title_en={How Antiplagiat detects paraphrased text},
title= "«Трое в лодке, нищета и собаки», или как Антиплагиат ищет парафраз",
note={Хабр. Соавтор статьи},
year={2018},
html={https://habr.com/ru/company/antiplagiat/blog/422941/},
abbr_en={Habr},
author_en = "Antiplagiat company",
note_en={It-blog. Article co-author.},
}

@unpublished{habr_tuda,
abbr={Хабр},
author= "Антиплагиат",
title= "«Туда и обратно» для нейронных сетей, или обзор применений автокодировщиков в анализе текстов",
title_en="An overview of autoencoders application in text analysis",
note={Хабр. Соавтор статьи},
year={2018},
html={https://habr.com/ru/company/antiplagiat/blog/418173/},
abbr_en={Habr},
author_en = "Antiplagiat company",
note_en={It-blog. Article co-author.},
}

@unpublished{habr_tuda,
abbr={Хабр},
author= "Антиплагиат",
title= "Трудности перевода: как найти плагиат с английского языка в русских научных статьях",
title_en="Challenges in translation: how to find a cross-lingual plagiarism from Russian into English",
note={Хабр. Соавтор статьи},
year={2018},
html={https://habr.com/ru/company/antiplagiat/blog/354142/},
abbr_en={Habr},
author_en = "Antiplagiat company",
note_en={It-blog. Article co-author.},
}


@unpublished{VBTA,
abbr = {ПО},
abbr_en = {Software},
author = "Бахтеев, О. Ю. and и, др.",
author_en = "Oleg Bakhteev et al.",
title = "Модуль поиска переводных текстовых заимствований с русского на английский язык",
title_en = "Cross-lingual textual reuse detection module for English-Russian language pair",
note={Свидетельство о регистрации ПО},
note_en={Software registration certificate},
year={2019},
html={https://www.elibrary.ru/item.asp?id=41532315}
}


